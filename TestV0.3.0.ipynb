{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "from paper_crawler.paper_crawler.spiders.semanticscholar import SemanticscholarSpider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\": {\"papers.json\": {\"format\": \"json\"}},\n",
    "        \"LOG_ENABLED\": False\n",
    "        #     \"LOG_LEVEL\": 'INFO',\n",
    "    }\n",
    ")\n",
    "process.crawl(SemanticscholarSpider, max_papers=200)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Crawled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"papers.json\") as f:\n",
    "    items = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f90720ed12e045ac84beb94c27271d6fb8ad48cf',\n",
       " 'title': 'The Lottery Ticket Hypothesis: Training Pruned Neural Networks',\n",
       " 'abstract': 'Recent work on neural network pruning indicates that, at training time, neural networks need to be significantly larger in size than is necessary to represent the eventual functions that they learn. This paper articulates a new hypothesis to explain this phenomenon. This conjecture, which we term the \"lottery ticket hypothesis,\" proposes that successful training depends on lucky random initialization of a smaller subcomponent of the network. Larger networks have more of these \"lottery ticketsâ€¦\\xa0',\n",
       " 'date': '2018',\n",
       " 'references': ['34f25a8704614163c4095b3ee2fc969b60de4698',\n",
       "  '1ff9a37d766e3a4f39757f5e1b235a42dacf18ff',\n",
       "  'b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d',\n",
       "  'cc46229a7c47f485e090857cbab6e6bf68c09811',\n",
       "  '642d0f49b7826adcf986616f4af77e736229990f',\n",
       "  '049fd80f52c0b1fa4d532945d95a24734b62bdf3',\n",
       "  '2dfef5635c8c44431ca3576081e6cfe6d65d4862',\n",
       "  '397de65a9a815ec39b3704a79341d687205bc80a',\n",
       "  'c2a1cb1612ba21e067a5c3ba478a8d73b796b77a',\n",
       "  'e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724'],\n",
       " 'authors': ['Jonathan Frankle', 'Michael Carbin']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=[{\"host\": \"localhost\", \"port\": 9200}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear previous index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'root_cause': [{'type': 'index_not_found_exception',\n",
       "    'reason': 'no such index [paper-index]',\n",
       "    'resource.type': 'index_or_alias',\n",
       "    'resource.id': 'paper-index',\n",
       "    'index_uuid': '_na_',\n",
       "    'index': 'paper-index'}],\n",
       "  'type': 'index_not_found_exception',\n",
       "  'reason': 'no such index [paper-index]',\n",
       "  'resource.type': 'index_or_alias',\n",
       "  'resource.id': 'paper-index',\n",
       "  'index_uuid': '_na_',\n",
       "  'index': 'paper-index'},\n",
       " 'status': 404}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(\"paper-index\", ignore=404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'paper-index'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index=\"paper-index\", ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create persistent layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import (\n",
    "    Document,\n",
    "    Date,\n",
    "    Nested,\n",
    "    Boolean,\n",
    "    analyzer,\n",
    "    InnerDoc,\n",
    "    Completion,\n",
    "    Keyword,\n",
    "    Text,\n",
    "    Integer,\n",
    "    Float,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(Document):\n",
    "    title = Text(fields={\"raw\": Keyword()})\n",
    "    date = Integer()\n",
    "    abstract = Text()\n",
    "    authors = Text()\n",
    "    references = Text()\n",
    "    page_rank = Float()\n",
    "\n",
    "    class Index:\n",
    "        name = \"paper-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the mappings in Elasticsearch\n",
    "Paper.init(using=es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import TransportError\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://elasticsearch-py.readthedocs.io/en/master/helpers.html#bulk-helpers\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/master/docs-bulk.html\n",
    "\n",
    "def gendata():\n",
    "    for idx, item in enumerate(items):\n",
    "        if item[\"date\"] == \"\" or not item[\"date\"].isdigit():\n",
    "            del item[\"date\"]\n",
    "        yield {\n",
    "            \"_index\": \"paper-index\",\n",
    "            \"_id\": item[\"id\"],\n",
    "            \"page_rank\": 1.0,\n",
    "            **item,\n",
    "        }\n",
    "\n",
    "bulk(es, gendata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    paper = Paper(meta={\"id\": item[\"id\"]}, page_rank=1.0, **item)\n",
    "    paper.save(using=es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcions for inserting items and clearing index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_utils(host=None):\n",
    "    if host is None:\n",
    "        host = {\"host\": \"localhost\", \"port\": 9200}\n",
    "    es = Elasticsearch(hosts=[{\"host\": \"localhost\", \"port\": 9200}])\n",
    "\n",
    "    def clear_index():\n",
    "        es.indices.delete(\"paper-index\", ignore=404)\n",
    "        es.indices.create(index=\"paper-index\", ignore=400)\n",
    "\n",
    "    def insert_items(items):\n",
    "        for item in items:\n",
    "            paper = Paper(meta={\"id\": item[\"id\"]}, **item)\n",
    "            paper.save(using=es)\n",
    "\n",
    "    return clear_index, insert_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear, insert = gen_utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = list(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = sorted(list(map(lambda x: x[\"id\"], all_papers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_matrix = np.zeros((len(all_ids), len(all_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_loc = dict()\n",
    "for index, paper_id in enumerate(all_ids):\n",
    "    id_loc[paper_id] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, paper_id in enumerate(all_ids):\n",
    "    paper = Paper.get(id=paper_id, using=es)\n",
    "    if paper.references is not None:\n",
    "        for reference_id in paper.references:\n",
    "            try:\n",
    "                p_matrix[index, id_loc[reference_id]] = 1\n",
    "            except KeyError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "N = len(all_ids)\n",
    "v = np.ones((1, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = np.sum(p_matrix, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first part is for rows having nonzero elements\n",
    "# second part is for dead-ends\n",
    "p_matrix = ((row_sums > 0) * 1) * (\n",
    "    (1 - alpha) * p_matrix / (row_sums + np.logical_not(row_sums > 0) * 1)\n",
    "    + alpha * v / N\n",
    ") + (np.logical_not(row_sums > 0) * 1) * v / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.ones((1, N)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    next_state = x0 @ p_matrix\n",
    "    if np.allclose(next_state, x0, rtol=0.0001):\n",
    "        break\n",
    "    x0 = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, paper_id in enumerate(all_ids):\n",
    "    paper = Paper.get(id=paper_id, using=es)\n",
    "    paper.update(page_rank=next_state[0, index], using=es)\n",
    "    paper.save(using=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata():\n",
    "    for index, paper_id in enumerate(all_ids):\n",
    "        yield {\n",
    "            \"_index\": \"paper-index\",\n",
    "            \"_id\": items[index][\"id\"],\n",
    "            \"_source\":{\"doc\":{\"page_rank\": next_state[0, index],}},\n",
    "            \"_op_type\": \"update\",\n",
    "        }\n",
    "\n",
    "bulk(es, gendata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 429\n",
    "body = \"\"\n",
    "for index, paper_id in enumerate(all_ids):\n",
    "    body += f'''{{ \"update\" : {{\"_id\" : \"{paper_id}\", \"_index\" : \"paper-index\"}} }}\n",
    "{{ \"doc\" : {{\"page_rank\" : {next_state[0, index]} }}}}\n",
    "'''\n",
    "    break\n",
    "body += \"\"\n",
    "res = es.bulk(body)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_search = \"lottery\"\n",
    "abstract_search = \"language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(\n",
    "    index=\"paper-index\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            # https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html#function-weight\n",
    "            \"function_score\": {\n",
    "                \"functions\": [\n",
    "                    {\"filter\": {\"match\": {\"title\": \"lottery\"}}, \"weight\": 20},\n",
    "                    {\n",
    "                        \"filter\": {\"match\": {\"abstract\": \"language\"}},\n",
    "                        \"weight\": 40,\n",
    "                    },\n",
    "                    # https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html\n",
    "                    {\n",
    "                        \"filter\": {\"range\": {\"date\": {\"gte\": 2018}}},\n",
    "                        \"weight\": 10,\n",
    "                    },\n",
    "                    # https://www.elastic.co/guide/en/elasticsearch/reference/current/static-scoring-signals.html\n",
    "                    # https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-rank-feature-query.html#rank-feature-query-saturation\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"script\": {\n",
    "                                \"source\": \"_score * saturation(doc['page_rank'].value, 10)\"\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.363636\n",
      "36.363636\n",
      "36.363636\n",
      "36.363636\n",
      "18.181818\n",
      "3.6363637\n",
      "3.6363637\n",
      "3.6363637\n",
      "3.6363637\n",
      "3.6363637\n"
     ]
    }
   ],
   "source": [
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'paper-index',\n",
       " '_type': '_doc',\n",
       " '_id': 'df2b0e26d0599ce3e70df8a9da02e51594e0e992',\n",
       " '_score': 36.363636,\n",
       " '_source': {'page_rank': 1.0,\n",
       "  'id': 'df2b0e26d0599ce3e70df8a9da02e51594e0e992',\n",
       "  'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
       "  'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).',\n",
       "  'date': '2019',\n",
       "  'references': ['0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38',\n",
       "   '0c47cad9729c38d9db1f75491b1ee4bd883a5d4e',\n",
       "   '204e3073870fae3d05bcbc2f6a8e263d9b72e776',\n",
       "   '8c1b00128e74f1cd92aede3959690615695d5101',\n",
       "   'ac11062f1f368d97f4c826c317bf50dcc13fdb59',\n",
       "   '93b8da28d006415866bf48f9a6e06b5242129195',\n",
       "   '687bac2d3320083eb4530bf18bb8f8f721477600',\n",
       "   'b9de9599d7241459db9213b5cdd7059696f5ef8d',\n",
       "   '27e98e09cf09bc13c913d01676e5f32624011050',\n",
       "   '7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d'],\n",
       "  'authors': ['Jacob Devlin', 'Ming-Wei Chang', 'Kristina Toutanova']}}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"hits\"][\"hits\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Search(using=es, index=\"paper-index\").query(\"match\", title=\"the lottery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Search(using=es, index=\"paper-index\").query(\"match\", id=\"323694313\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in response:\n",
    "    print(hit.meta.score, hit.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by calling .search we get back a standard Search object\n",
    "s = Paper.search(using=es)\n",
    "# the search is already limited to the index and doc_type of our document\n",
    "s = s.query(\"match\", title=\"the lottery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.631361 The Lottery Ticket Hypothesis: Training Pruned Neural Networks 1.0\n",
      "1.8374821 The projection of the retina in the cat. 1.0\n",
      "1.7945862 The projection of the lateral geniculate nucleus upon the cortex in the cat 1.0\n",
      "1.7697966 THE EFFECTS OF SPATIAL SUMMATION IN THE RETINA ON THE EXCITATION OF THE FIBERS OF THE OPTIC NERVE 1.0\n",
      "1.752861 The Representation of the Visual Field on the Calcarine Cortex 1.0\n",
      "1.752861 The projection of the retina in the lateral geniculate body 1.0\n",
      "1.752861 The Spectral Properties of the Visual Receptors of the Cat 1.0\n",
      "1.752861 The spatial selectivity of the visual cells of the cat. 1.0\n",
      "1.752861 THE FUNCTION OF THE CALLOSAL CONNECTIONS OF THE VISUAL CORTEX. 1.0\n",
      "1.752861 The cytoarchitectonic organization of the spinal cord in the cat. 1.0\n"
     ]
    }
   ],
   "source": [
    "for hit in response:\n",
    "    print(hit.meta.score, hit.title, hit.page_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
